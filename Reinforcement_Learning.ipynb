{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942e9bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf06179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/721.7 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/721.7 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/721.7 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/721.7 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/721.7 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/721.7 kB ? eta -:--:--\n",
      "     -------------------------- --------- 524.3/721.7 kB 199.8 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 524.3/721.7 kB 199.8 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 524.3/721.7 kB 199.8 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 524.3/721.7 kB 199.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 721.7/721.7 kB 222.9 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\shali\\appdata\\roaming\\python\\python312\\site-packages (from gym) (2.3.5)\n",
      "Collecting cloudpickle>=1.2.0 (from gym)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gym_notices>=0.0.4 (from gym)\n",
      "  Downloading gym_notices-0.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading gym_notices-0.1.0-py3-none-any.whl (3.3 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827739 sha256=31ee2929ec32f9ed2fe59cb2b3337feb22aab2d067a317fa1f3ae0022af45f71\n",
      "  Stored in directory: c:\\users\\shali\\appdata\\local\\pip\\cache\\wheels\\95\\51\\6c\\9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n",
      "Successfully built gym\n",
      "Installing collected packages: gym_notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-3.1.2 gym-0.26.2 gym_notices-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd136a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\shali\\appdata\\roaming\\python\\python312\\site-packages (2.3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ab8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3d83a",
   "metadata": {},
   "source": [
    "What is Reinforcement Learning?\n",
    "\n",
    "Reinforcement Learning is a way of teaching a computer like we train a small child or a pet.\n",
    "\n",
    "If the child does something good ‚Üí we give chocolate \n",
    "If the child does something wrong ‚Üí we say ‚ÄúNo‚Äù\n",
    "\n",
    "Over time, the child learns what is good and what is bad.\n",
    "\n",
    "That‚Äôs exactly how RL works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f6806",
   "metadata": {},
   "source": [
    "Basic Idea of RL\n",
    "\n",
    "There are 4 main parts:\n",
    "\n",
    "Agent ‚Üí The learner (like a robot or AI)\n",
    "\n",
    "Environment ‚Üí The world around it\n",
    "\n",
    "Action ‚Üí What the agent does\n",
    "\n",
    "Reward ‚Üí Feedback (good or bad)\n",
    "\n",
    "Example (Game Example)\n",
    "\n",
    "Imagine playing a video game:\n",
    "\n",
    "You = Agent\n",
    "\n",
    "Game = Environment\n",
    "\n",
    "Move left/right/jump = Actions\n",
    "\n",
    "Points = Reward\n",
    "\n",
    "If you get more points ‚Üí you repeat that strategy\n",
    "If you lose ‚Üí you try something different\n",
    "\n",
    "That learning process = Reinforcement Learning.\n",
    "\n",
    "How RL Actually Works (Simple Flow)\n",
    "\n",
    "Agent looks at situation.\n",
    "\n",
    "Agent takes an action.\n",
    "\n",
    "Environment gives reward.\n",
    "\n",
    "Agent updates its knowledge.\n",
    "\n",
    "Repeat again and again.\n",
    "\n",
    "This is called Trial and Error Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5856a",
   "metadata": {},
   "source": [
    " Important RL Concepts (Very Simple)\n",
    "1Ô∏è Policy\n",
    "\n",
    "Policy = Strategy\n",
    "\n",
    "It answers:\n",
    "\"What action should I take in this situation?\"\n",
    "\n",
    "Example:\n",
    "If ball comes fast ‚Üí move right.\n",
    "\n",
    "2 Reward\n",
    "\n",
    "Reward tells if action was good or bad.\n",
    "\n",
    "+10 ‚Üí Good\n",
    "-5 ‚Üí Bad\n",
    "\n",
    "The goal of RL is:\n",
    "\n",
    "Maximize total reward\n",
    "\n",
    "3 Exploration vs Exploitation\n",
    "\n",
    "Very important concept!\n",
    "\n",
    "Exploration ‚Üí Try new things\n",
    "\n",
    "Exploitation ‚Üí Use what already works\n",
    "\n",
    "Example:\n",
    "You go to restaurant.\n",
    "\n",
    "Try new dish (exploration)\n",
    "\n",
    "Order your favorite dish (exploitation)\n",
    "\n",
    "RL balances both.\n",
    "\n",
    " Types of RL Algorithms (Human Way Explanation)\n",
    "\n",
    "Now let‚Äôs understand main algorithms in simple words.\n",
    "\n",
    "Q-Learning\n",
    "\n",
    "Very popular and basic RL algorithm.\n",
    "\n",
    "Think of it like a big table.\n",
    "\n",
    "The table stores:\n",
    "\n",
    "Situation\n",
    "\n",
    "Action\n",
    "\n",
    "Expected reward\n",
    "\n",
    "So next time agent sees same situation ‚Üí\n",
    "It checks the table and picks the best action.\n",
    "\n",
    "Good for:\n",
    "\n",
    "Small problems\n",
    "\n",
    "Simple environments\n",
    "\n",
    "Deep Q-Network (DQN)\n",
    "\n",
    "When problem becomes big and complex,\n",
    "normal table becomes too large.\n",
    "\n",
    "So instead of table ‚Üí\n",
    "We use a Neural Network (Deep Learning).\n",
    "\n",
    "It predicts:\n",
    "\"How good is this action?\"\n",
    "\n",
    "Used in:\n",
    "\n",
    "Video games\n",
    "\n",
    "Robotics\n",
    "\n",
    "Complex environments\n",
    "\n",
    "Policy Gradient\n",
    "\n",
    "Instead of learning values,\n",
    "It directly learns the strategy.\n",
    "\n",
    "It improves the policy step by step.\n",
    "\n",
    "More advanced.\n",
    "Used in:\n",
    "\n",
    "Continuous actions\n",
    "\n",
    "Robotics\n",
    "\n",
    "Self-driving systems\n",
    "\n",
    "-Critic\n",
    "\n",
    "Combination of two things:\n",
    "\n",
    "Actor ‚Üí Decides action\n",
    "\n",
    "Critic ‚Üí Checks if action was good\n",
    "\n",
    "Very powerful.\n",
    "Used in modern AI systems.\n",
    "\n",
    "Where RL is Used in Real Life?\n",
    "\n",
    "Self-driving cars üöó\n",
    "\n",
    "Game AI (like AlphaGo)\n",
    "\n",
    "Robots ü§ñ\n",
    "\n",
    "Stock trading\n",
    "\n",
    "Recommendation systems\n",
    "\n",
    "Chatbots\n",
    "\n",
    " Main Goal of RL\n",
    "\n",
    "The main goal is:\n",
    "\n",
    "Learn best behavior by maximizing reward over time.\n",
    "\n",
    "Not instant reward ‚Äî\n",
    "but long-term reward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
